{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impact of minority shareholdings on innovation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first steps of our research agenda were to understand, choose and clean the data we would later use for regression. \n",
    "This notebook mainly deals with the creation of the database. We used data from Orbis and from Zephir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collection and cleaning of the data from Zephir** \\\n",
    "From Zephir, we extracted all minority deals (with pieces of information about it) data regarding deals made by companies. \\\n",
    "Minority deals are deals with an acquired stake below 50%. \n",
    "As we could only download 10.000 rows by 10.000 rows, we had to concatenate 16 small databases. They are is the 'data_eco' file. \n",
    "We took advantage of this first step for converting the date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_eco/MS_final16.xlsx', 'data_eco/MS_final2.xlsx', 'data_eco/MS_final3.xlsx', 'data_eco/MS_final8.xlsx', 'data_eco/MS_final10.xlsx', 'data_eco/MS_final4.xlsx', 'data_eco/MS_final5.xlsx', 'data_eco/MS_final11.xlsx', 'data_eco/MS_final9.xlsx', 'data_eco/MS_final6.xlsx', 'data_eco/MS_final12.xlsx', 'data_eco/MS_final13.xlsx', 'data_eco/MS_final7.xlsx', 'data_eco/MS_final14.xlsx', 'data_eco/MS_final15.xlsx', 'data_eco/MS_final1.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# concaténation de tout les fichiers + nettoyage sommaire des données\n",
    "path = \"data_eco\"\n",
    "folder = os.listdir(path)\n",
    "files_xls = []\n",
    "def date_parser(x):\n",
    "    if type(x) == int:\n",
    "        y = pd.to_datetime(pd.to_datetime(x, unit='D', origin='1899-12-30').strftime(format='%d-%m-%Y'))\n",
    "    else:\n",
    "        y = pd.to_datetime(x, dayfirst=True)\n",
    "    return y\n",
    "for file in folder :\n",
    "    files_xls.append(f'{path}/{file}')\n",
    "print(files_xls)\n",
    "df = pd.DataFrame()\n",
    "for f in files_xls:\n",
    "    data = pd.read_excel(f, 'Results', converters={'Completed date':date_parser, 'Assumed completion date':date_parser })\n",
    "    df = df.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of this database are : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3369: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# save of the concateta databases. \n",
    "#df.to_csv('data.csv', index = True)\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **second step** was to clean the data. \\\n",
    "1_ We had to remove the rows that were empty. \\\n",
    "2_ Verifie wether the deal acquired stake were actualy below 50%, and remove the row if not. \\\n",
    "3_ Remove acquisitions with a missing date. 2 different dates were mentionned in the database. When \"completion date\" was mentionned, \"Assumed completion date\" wasn't and vice versa. We decided to aggragate those 2 columns in \"Completed or assumed date\" \\\n",
    "4_ Remove acquisitions where the seller (\"Acquiror\") and the \"Target\" were one and the same company. \\\n",
    "5_ Remove acquisitions with missing data on the target or acquiror's country code. \n",
    "6_ Finnaly, we only kept domestic acquisitions by removing acquisition with different target country code and acquiror contry code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/617938333.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Completed or assumed date'][i] = df['Assumed completion date'][i]\n"
     ]
    }
   ],
   "source": [
    "shape_initiale = df.shape[0]\n",
    "#supprimer les lignes vident de données\n",
    "df.dropna(axis=0, subset=['Unnamed: 0','Target BvD ID number', 'Acquiror BvD ID number',\"Acquired stake (%)\" ], how='any', inplace=True)\n",
    "shape_with_empty_rows = shape_initiale - df.shape[0]\n",
    "shape_without_empty_rows = df.shape[0]\n",
    "\n",
    "#Vérification de si les acquired stake sont bien inférieurs à 50%\n",
    "\n",
    "df = df[df[\"Acquired stake (%)\"] != \"Unknown %\"]\n",
    "shape_with_unknown_acquired_stake = shape_without_empty_rows - df.shape[0]\n",
    "shape_without_unknown_acquired_stake = df.shape[0]\n",
    "\n",
    "def replace(x):\n",
    "    if type(x)==str :\n",
    "        if \"Unknown majority\" in x:\n",
    "            x = str(60)\n",
    "        elif 'Unknown minority' in x:\n",
    "            x = str(1)\n",
    "        if '\\n' in x:\n",
    "            x = str(60)\n",
    "    \n",
    "    x = float(x)\n",
    "    return x\n",
    "df[\"Acquired stake (%)\"] = df[\"Acquired stake (%)\"].map(replace)\n",
    "df['Final stake (%)'] = df['Final stake (%)'].map(replace)\n",
    "df = df[df['Acquired stake (%)'] < 50]\n",
    "df = df[df['Final stake (%)'] < 50]\n",
    "\n",
    "shape_with_acquired_stake_over_50 = shape_without_unknown_acquired_stake - df.shape[0]\n",
    "shape_acquired_stake_under_50 = df.shape[0]\n",
    "\n",
    "#suppressoin des acquisitions sans date\n",
    "df.dropna(axis=0,how='all', subset = ['Completed date','Assumed completion date'], inplace=True)\n",
    "shape_acquisition_with_date =  shape_acquired_stake_under_50- df.shape[0]\n",
    "shape_acquisition_with_date = df.shape[0]\n",
    "\n",
    "\n",
    "#supprimer les acquisitions où le seller et le buyer sont les mêmes\n",
    "df = df[df['Target BvD ID number'] != df['Acquiror BvD ID number']]\n",
    "shape_acquiror_egal_target =  shape_acquisition_with_date - df.shape[0]\n",
    "shape_without_acquiror_egal_target = df.shape[0]\n",
    "\n",
    "# suppressions des acquisitions pour lesquelles il manque des données sur le pays des Target et des acquirors\n",
    "df = df[(df['Target country code'].notna())|(df['Acquiror country code'].notna())]\n",
    "# on ne garde que les acquisitions domestiques \n",
    "df = df[(df['Target country code'] == df['Acquiror country code'])]\n",
    "shape_domestic = df.shape[0]\n",
    "shape_cross_country = shape_without_acquiror_egal_target - df.shape[0]\n",
    "\n",
    "#réindexer\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#création d'une nouvelle colonne Completed or assumed date contenant la date  \n",
    "df['Completed or assumed date'] = df['Completed date']\n",
    "for i in range(df.shape[0]):\n",
    "    if type(df['Completed date'][i]) == float:\n",
    "        df['Completed or assumed date'][i] = df['Assumed completion date'][i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** \\\n",
    "From Zephir, we extracted SIC codes and Nace codes of the target companies, acquired companies and their parents. SIC Codes and Nace codes are needed in order to determine wether a deal is horizontal or not. \\\n",
    "\n",
    "We only collected the data of the companies of the top 30 countries with the most deals.\\\n",
    "Indeed, as extracting data from Orbis is very time consumming, and because regressions can only be done on countries with a lot of deals, we decided not to extract data about all the companies referenced on Orbis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the 30 first countries.\n",
    "List_major_countries = df['Target country code'].value_counts()[:30]\n",
    "# list of the target companies\n",
    "list_target = df[df['Target country code'].isin(List_major_countries.index)]['Target BvD ID number'].values\n",
    "# list of the acquiror companies\n",
    "list_acquiror = df[df['Acquiror country code'].isin(List_major_countries.index)]['Acquiror BvD ID number'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dowloading the data, we obtained 4 excel databases. 2 regarding the target companies and 2 other regarding the acquiror companies and their parent companies. They are un the 'Zephir_data' folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** file size (8068376) not 512 + multiple of sector size (512)\n",
      "WARNING *** file size (10696885) not 512 + multiple of sector size (512)\n",
      "WARNING *** file size (7190425) not 512 + multiple of sector size (512)\n",
      "WARNING *** file size (9734975) not 512 + multiple of sector size (512)\n"
     ]
    }
   ],
   "source": [
    "target1 = pd.read_excel('Zephir_data/Target NACE1.xls', 'Results')\n",
    "target2 = pd.read_excel('Zephir_data/Target NACE2.xls', 'Results')\n",
    "\n",
    "acquiror_parent2 = pd.read_excel('Zephir_data/Acquiror & CHS - NACE2.xls', 'Results')\n",
    "acquiror_parent1 = pd.read_excel('Zephir_data/Acquiror & CSH NACE1.xls', 'Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim was now : \\\n",
    "1 - to concatenate target1 with target2, and acquiror_parent1 with acquiror_parent2. \\\n",
    "2 - to join target with data on Target BvD ID number, and acquiror_parent on Acquiror BvD ID number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concaténation fichiers targets et acquirors\n",
    "target = pd.concat([target1,target2], ignore_index=True)\n",
    "acquiror_parents = pd.concat([acquiror_parent1,acquiror_parent2])\n",
    "\n",
    "# Nettoyage de Target et Acquiror\n",
    "target.dropna(axis=0,subset=['NACE Rev. 2, core code (4 digits)','NACE Rev. 2, secondary code(s)'], how='all', inplace=True)\n",
    "target['Target BvD ID number'] = target['BvD ID number']\n",
    "target = target[['Target BvD ID number','NACE Rev. 2, core code (4 digits)','NACE Rev. 2, secondary code(s)']]\n",
    "target.set_index('Target BvD ID number',inplace=True)\n",
    "acquiror_parents['Acquiror BvD ID number'] = acquiror_parents['BvD ID number']\n",
    "acquiror_parents.dropna(axis=0, subset=['NACE Rev. 2, core code (4 digits)','NACE Rev. 2, secondary code(s)','CSH - NACE,\\nCore code'], how='all', inplace=True)\n",
    "acquiror_parents = acquiror_parents[['Acquiror BvD ID number','NACE Rev. 2, core code (4 digits)','NACE Rev. 2, secondary code(s)','CSH - NACE,\\nCore code']]\n",
    "acquiror_parents.set_index('Acquiror BvD ID number', inplace=True)\n",
    "acquiror_parents.rename(columns={'NACE Rev. 2, core code (4 digits)':'primary acquiror NACE code',\n",
    " 'NACE Rev. 2, secondary code(s)':'secondary acquiror NACE code(s)',\n",
    " 'CSH - NACE,\\nCore code':'parent NACE code(s)'}, inplace=True)\n",
    "\n",
    " # création d'un double index pour df\n",
    "df.set_index(['Target BvD ID number','Acquiror BvD ID number'],inplace=True)\n",
    "\n",
    "# join table df and target on Target BvD ID number\n",
    "df = df.join(target, on='Target BvD ID number')\n",
    "#join table df and acquiror_parents on Acquiror BvD ID number\n",
    "df = df.join(acquiror_parents, on='Acquiror BvD ID number')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now was the time to remove acquisitions made by investors. Are considered as acquisition made by investors : \n",
    "- acquisitions where the acquiror is an investor \n",
    "- acquisitions where the parent company of the acquiror is an investor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/2037445781.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Acquiror NACE code(s)'][i] += '\\n' + df['secondary acquiror NACE code(s)'][i]\n",
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/2037445781.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Target NACE code(s)'][i] += '\\n' + df['NACE Rev. 2, secondary code(s)'][i]\n",
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/2037445781.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Target NACE code(s)'][i] = df['NACE Rev. 2, secondary code(s)'][i]\n",
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/2037445781.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Acquiror NACE code(s)'][i] = df['secondary acquiror NACE code(s)'][i]\n"
     ]
    }
   ],
   "source": [
    "# creation 1 colone Target NACE Code(s) et 1 colonne Acquiror NACE Code(s)\n",
    "df['Acquiror NACE code(s)'] = df['primary acquiror NACE code'] \n",
    "df['Target NACE code(s)'] = df['NACE Rev. 2, core code (4 digits)'] \n",
    "for i in range(df.shape[0]):\n",
    "    if type(df['Acquiror NACE code(s)'][i]) == str:\n",
    "        if type(df['secondary acquiror NACE code(s)'][i]) == str:\n",
    "            df['Acquiror NACE code(s)'][i] += '\\n' + df['secondary acquiror NACE code(s)'][i]\n",
    "    else :\n",
    "        if type(df['secondary acquiror NACE code(s)'][i]) == str:\n",
    "            df['Acquiror NACE code(s)'][i] = df['secondary acquiror NACE code(s)'][i]\n",
    "    if type(df['Target NACE code(s)'][i]) == str:\n",
    "        if type(df['NACE Rev. 2, secondary code(s)'][i]) == str:\n",
    "            df['Target NACE code(s)'][i] += '\\n' + df['NACE Rev. 2, secondary code(s)'][i]\n",
    "    else :\n",
    "        if type(df['NACE Rev. 2, secondary code(s)'][i]) == str:\n",
    "            df['Target NACE code(s)'][i] = df['NACE Rev. 2, secondary code(s)'][i]\n",
    "\n",
    "\n",
    "df2 = copy.deepcopy(df)\n",
    "shape_after_join = df2.shape[0]\n",
    "df2.drop(['NACE Rev. 2, core code (4 digits)','NACE Rev. 2, secondary code(s)','primary acquiror NACE code','secondary acquiror NACE code(s)'], axis=1, inplace=True)\n",
    "\n",
    "#on retire les acquisiton lorsqu'on ne connaît pas le SIC code et le Nace code des Targets ou des Acquiror\n",
    "df2.dropna(axis = 0, subset=['Target NACE code(s)','Target US SIC code(s)'], how = 'all', inplace = True)\n",
    "df2.dropna(axis = 0, subset=[\"Acquiror NACE code(s)\", 'Acquiror US SIC code(s)'], how = 'all', inplace = True)\n",
    "\n",
    "\n",
    "# mise en forme des Nace dodes et des SIC codes\n",
    "def fonction_NACE(x):\n",
    "    if type(x) == str:\n",
    "        try : \n",
    "            x = x.split('\\n')\n",
    "        except :\n",
    "            x=np.nan\n",
    "    else : \n",
    "        x = [x]\n",
    "    return x\n",
    "\n",
    "def fonction_SIC(x):\n",
    "    if type(x) == str:\n",
    "        x = x.split('/')\n",
    "    else :\n",
    "        x = [x]\n",
    "    return x\n",
    "df2['Acquiror NACE code(s)'] = df2['Acquiror NACE code(s)'].map(fonction_NACE)\n",
    "df2['Target NACE code(s)'] = df2['Target NACE code(s)'].map(fonction_NACE)\n",
    "df2['parent NACE code(s)'] = df2['parent NACE code(s)'].map(fonction_NACE)\n",
    "df2['Target US SIC code(s)'] = df2['Target US SIC code(s)'].map(fonction_SIC)\n",
    "df2['Acquiror US SIC code(s)'] = df2['Acquiror US SIC code(s)'].map(fonction_SIC)\n",
    "\n",
    "\n",
    "# retirer les acquisitions faites par des investisseurs\n",
    "# les acquisitions faites par des investeurs sont celles ou l'acquiror ET le parent de l'acquiror sont des investisseurs\n",
    "def find_investor_ac(x):\n",
    "    for element in x:\n",
    "        if type(element) == str :\n",
    "            if '64' in element[:2]:\n",
    "                x = False\n",
    "            else : \n",
    "                x = True\n",
    "        else : \n",
    "            x = False\n",
    "    return x\n",
    "\n",
    "def find_investor_par(x):\n",
    "    if type (x) == str:\n",
    "        if '64' in x[:2]:\n",
    "            x = False\n",
    "        else :\n",
    "            x = True\n",
    "    else : \n",
    "        x = False\n",
    "    return x\n",
    "\n",
    "mask_investor_1 = df2['Acquiror NACE code(s)'].map(find_investor_ac)\n",
    "mask_investor_2 = df2['parent NACE code(s)'].map(find_investor_par)\n",
    "liste = [] \n",
    "for i, element in enumerate(mask_investor_1):\n",
    "    if element == False :\n",
    "        if element == mask_investor_2[i]:\n",
    "            liste.append(False)\n",
    "        else :\n",
    "            liste.append(True)\n",
    "    else : \n",
    "        liste.append(True)\n",
    "df2 = df2[liste]\n",
    "shape_acquisition_by_investor = shape_after_join - df2.shape[0]\n",
    "shape_without_investor = df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we decided to create 4 different tables : \n",
    "- horizontal deals with data about the target company  : Target_horizontal \n",
    "- horizontal deals with data about the acquiror company : Acquiror_horizontal \n",
    "- non horizontal deals with data about the target company : Target_non_horizontal \n",
    "- non horizontal deals with data about the acquiror company : Acquiror_non_horizontal \n",
    "\n",
    "In order to do so, it is needed to separate horizontal from non_horizontal acquisitions.\\\n",
    "A deal is considered horizontal when : \n",
    "- the target and the acquiror evolve in the same sector of activity (the target SIC code or Nace code  and acquiror SIC code or Nace code are the same). \n",
    "- the target and the parent of the acquiror evolve in the same sector of activity (target Nace code and acquiror parent Nace code are the same).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target BvD ID number</th>\n",
       "      <th>Acquiror BvD ID number</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Deal Number</th>\n",
       "      <th>Deal type</th>\n",
       "      <th>Deal status</th>\n",
       "      <th>Deal value\\nm EUR</th>\n",
       "      <th>Completed date</th>\n",
       "      <th>Assumed completion date</th>\n",
       "      <th>...</th>\n",
       "      <th>Acquiror ISH Name</th>\n",
       "      <th>Acquiror ISH BvD number</th>\n",
       "      <th>Acquiror ISH ISO country code</th>\n",
       "      <th>Acquiror ISH Direct %</th>\n",
       "      <th>Acquiror ISH Total %</th>\n",
       "      <th>Completed or assumed date</th>\n",
       "      <th>parent NACE code(s)</th>\n",
       "      <th>Acquiror NACE code(s)</th>\n",
       "      <th>Target NACE code(s)</th>\n",
       "      <th>horizontal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FI09238664</td>\n",
       "      <td>FI09507502</td>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.397950e+05</td>\n",
       "      <td>Minority stake 40%</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-05-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-05-22</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[5813]</td>\n",
       "      <td>[5320]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SE5560499690</td>\n",
       "      <td>SE5561980128</td>\n",
       "      <td>12</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.398480e+05</td>\n",
       "      <td>Minority stake increased to 5.5%</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>SWEDBANK ROBUR AB</td>\n",
       "      <td>SE5561103895</td>\n",
       "      <td>SE</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[6419, 6619]</td>\n",
       "      <td>[6630]</td>\n",
       "      <td>[5829]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RU99263319</td>\n",
       "      <td>RU09801500</td>\n",
       "      <td>13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.398580e+05</td>\n",
       "      <td>Minority stake 25%</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-05-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-05-18</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[6419, 6492, 6499, 6612, 6619]</td>\n",
       "      <td>[6491, 6499, 6810, 6820, 6830, 6900, 7310, 771...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU07506317</td>\n",
       "      <td>RU56467052</td>\n",
       "      <td>14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.398640e+05</td>\n",
       "      <td>Minority stake 20.16%</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-05-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ROSTEC</td>\n",
       "      <td>RU94137372</td>\n",
       "      <td>RU</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2007-05-21</td>\n",
       "      <td>[8411, 8411, -]</td>\n",
       "      <td>[4669, 4612, 4614, 4669, 4675, 4690, 6311]</td>\n",
       "      <td>[3030, 3030]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RU12169000</td>\n",
       "      <td>RU57497960</td>\n",
       "      <td>16</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.399130e+05</td>\n",
       "      <td>Minority stake 6.87%</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-05-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-05-18</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[4720, 1071, 1072, 4611, 4612, 4621]</td>\n",
       "      <td>[6820, 2211, 4520, 4530, 4930, 4941, 7711, 7739]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47657</th>\n",
       "      <td>US208481962</td>\n",
       "      <td>US470813844</td>\n",
       "      <td>9986</td>\n",
       "      <td>9987.0</td>\n",
       "      <td>1.601447e+09</td>\n",
       "      <td>Minority stake increased from 2.531% to 6.445%</td>\n",
       "      <td>Completed</td>\n",
       "      <td>108.09*</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[6500]</td>\n",
       "      <td>[2910, 2813, 2899, 2932]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47658</th>\n",
       "      <td>CN31136PC</td>\n",
       "      <td>CN9381915283</td>\n",
       "      <td>9987</td>\n",
       "      <td>9988.0</td>\n",
       "      <td>1.943250e+09</td>\n",
       "      <td>Minority stake 4.99%</td>\n",
       "      <td>Completed</td>\n",
       "      <td>108.05*</td>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>JIANGXI TRANSPORT AND SHIPPING OFFICE</td>\n",
       "      <td>CN9457380403</td>\n",
       "      <td>CN</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[4221]</td>\n",
       "      <td>[4211, 5229]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47659</th>\n",
       "      <td>TH0105552133918</td>\n",
       "      <td>TH0115557021034</td>\n",
       "      <td>9989</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>1.943236e+09</td>\n",
       "      <td>Minority stake increased from 4.71% to 25.23%</td>\n",
       "      <td>Completed Assumed</td>\n",
       "      <td>108.04*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[6832]</td>\n",
       "      <td>[4110, 6820]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47660</th>\n",
       "      <td>ZA200801569606</td>\n",
       "      <td>ZA195700197906</td>\n",
       "      <td>9993</td>\n",
       "      <td>9994.0</td>\n",
       "      <td>1.941624e+09</td>\n",
       "      <td>Minority stake increased from 24.52% to 29.38%</td>\n",
       "      <td>Completed</td>\n",
       "      <td>108.01*</td>\n",
       "      <td>2021-11-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-11-29</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[0729, 2441]</td>\n",
       "      <td>[2892]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47661</th>\n",
       "      <td>CN9410013436</td>\n",
       "      <td>CN9467251193</td>\n",
       "      <td>9994</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>1.943220e+09</td>\n",
       "      <td>Capital increase 35.93%</td>\n",
       "      <td>Completed</td>\n",
       "      <td>108.00*</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CHINA CONSTRUCTION BANK CO., LTD</td>\n",
       "      <td>CNFEB48206</td>\n",
       "      <td>CN</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>[-, 8413, 6619, 6619, 6419]</td>\n",
       "      <td>[6619]</td>\n",
       "      <td>[3700]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47662 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target BvD ID number Acquiror BvD ID number  Unnamed: 0  Unnamed: 0.1  \\\n",
       "0               FI09238664             FI09507502          11          12.0   \n",
       "1             SE5560499690           SE5561980128          12          13.0   \n",
       "2               RU99263319             RU09801500          13          14.0   \n",
       "3               RU07506317             RU56467052          14          15.0   \n",
       "4               RU12169000             RU57497960          16          17.0   \n",
       "...                    ...                    ...         ...           ...   \n",
       "47657          US208481962            US470813844        9986        9987.0   \n",
       "47658            CN31136PC           CN9381915283        9987        9988.0   \n",
       "47659      TH0105552133918        TH0115557021034        9989        9990.0   \n",
       "47660       ZA200801569606         ZA195700197906        9993        9994.0   \n",
       "47661         CN9410013436           CN9467251193        9994        9995.0   \n",
       "\n",
       "        Deal Number                                       Deal type  \\\n",
       "0      5.397950e+05                              Minority stake 40%   \n",
       "1      5.398480e+05                Minority stake increased to 5.5%   \n",
       "2      5.398580e+05                              Minority stake 25%   \n",
       "3      5.398640e+05                           Minority stake 20.16%   \n",
       "4      5.399130e+05                            Minority stake 6.87%   \n",
       "...             ...                                             ...   \n",
       "47657  1.601447e+09  Minority stake increased from 2.531% to 6.445%   \n",
       "47658  1.943250e+09                            Minority stake 4.99%   \n",
       "47659  1.943236e+09   Minority stake increased from 4.71% to 25.23%   \n",
       "47660  1.941624e+09  Minority stake increased from 24.52% to 29.38%   \n",
       "47661  1.943220e+09                         Capital increase 35.93%   \n",
       "\n",
       "             Deal status Deal value\\nm EUR Completed date  \\\n",
       "0              Completed               NaN     2007-05-22   \n",
       "1              Completed               NaN     2007-05-23   \n",
       "2              Completed               NaN     2007-05-18   \n",
       "3              Completed               NaN     2007-05-21   \n",
       "4              Completed               NaN     2007-05-18   \n",
       "...                  ...               ...            ...   \n",
       "47657          Completed           108.09*     2012-12-31   \n",
       "47658          Completed           108.05*     2021-02-08   \n",
       "47659  Completed Assumed           108.04*            NaN   \n",
       "47660          Completed           108.01*     2021-11-29   \n",
       "47661          Completed           108.00*     2020-03-11   \n",
       "\n",
       "      Assumed completion date  ...                      Acquiror ISH Name  \\\n",
       "0                         NaN  ...                                    NaN   \n",
       "1                         NaN  ...                      SWEDBANK ROBUR AB   \n",
       "2                         NaN  ...                                    NaN   \n",
       "3                         NaN  ...                                 ROSTEC   \n",
       "4                         NaN  ...                                    NaN   \n",
       "...                       ...  ...                                    ...   \n",
       "47657                     NaN  ...                                    NaN   \n",
       "47658                     NaN  ...  JIANGXI TRANSPORT AND SHIPPING OFFICE   \n",
       "47659              2021-01-29  ...                                    NaN   \n",
       "47660                     NaN  ...                                    NaN   \n",
       "47661                     NaN  ...       CHINA CONSTRUCTION BANK CO., LTD   \n",
       "\n",
       "      Acquiror ISH BvD number Acquiror ISH ISO country code  \\\n",
       "0                         NaN                           NaN   \n",
       "1                SE5561103895                            SE   \n",
       "2                         NaN                           NaN   \n",
       "3                  RU94137372                            RU   \n",
       "4                         NaN                           NaN   \n",
       "...                       ...                           ...   \n",
       "47657                     NaN                           NaN   \n",
       "47658            CN9457380403                            CN   \n",
       "47659                     NaN                           NaN   \n",
       "47660                     NaN                           NaN   \n",
       "47661              CNFEB48206                            CN   \n",
       "\n",
       "       Acquiror ISH Direct %  Acquiror ISH Total % Completed or assumed date  \\\n",
       "0                        NaN                   NaN                2007-05-22   \n",
       "1                     100.00                100.00                2007-05-23   \n",
       "2                        NaN                   NaN                2007-05-18   \n",
       "3                     100.00                100.00                2007-05-21   \n",
       "4                        NaN                   NaN                2007-05-18   \n",
       "...                      ...                   ...                       ...   \n",
       "47657                    NaN                   NaN                2012-12-31   \n",
       "47658                 100.00                100.00                2021-02-08   \n",
       "47659                    NaN                   NaN                2021-01-29   \n",
       "47660                    NaN                   NaN                2021-11-29   \n",
       "47661                 100.00                100.00                2020-03-11   \n",
       "\n",
       "               parent NACE code(s)  \\\n",
       "0                            [nan]   \n",
       "1                     [6419, 6619]   \n",
       "2                            [nan]   \n",
       "3                  [8411, 8411, -]   \n",
       "4                            [nan]   \n",
       "...                            ...   \n",
       "47657                        [nan]   \n",
       "47658                        [nan]   \n",
       "47659                        [nan]   \n",
       "47660                        [nan]   \n",
       "47661  [-, 8413, 6619, 6619, 6419]   \n",
       "\n",
       "                            Acquiror NACE code(s)  \\\n",
       "0                                          [5813]   \n",
       "1                                          [6630]   \n",
       "2                  [6419, 6492, 6499, 6612, 6619]   \n",
       "3      [4669, 4612, 4614, 4669, 4675, 4690, 6311]   \n",
       "4            [4720, 1071, 1072, 4611, 4612, 4621]   \n",
       "...                                           ...   \n",
       "47657                                      [6500]   \n",
       "47658                                      [4221]   \n",
       "47659                                      [6832]   \n",
       "47660                                [0729, 2441]   \n",
       "47661                                      [6619]   \n",
       "\n",
       "                                     Target NACE code(s) horizontal  \n",
       "0                                                 [5320]       True  \n",
       "1                                                 [5829]       True  \n",
       "2      [6491, 6499, 6810, 6820, 6830, 6900, 7310, 771...       True  \n",
       "3                                           [3030, 3030]       True  \n",
       "4       [6820, 2211, 4520, 4530, 4930, 4941, 7711, 7739]       True  \n",
       "...                                                  ...        ...  \n",
       "47657                           [2910, 2813, 2899, 2932]       True  \n",
       "47658                                       [4211, 5229]       True  \n",
       "47659                                       [4110, 6820]       True  \n",
       "47660                                             [2892]       True  \n",
       "47661                                             [3700]       True  \n",
       "\n",
       "[47662 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# horizontal acquisitions\n",
    "# sont considérées comme horizontales les acquisitions où :\n",
    "# - target et acquiror évoluent dans le même secteur d'activité (Nace Code + SIC Code)\n",
    "# - target et parent de l'acquiror évoluent dans le même secteur d'activité (Nace code)\n",
    "df2['horizontal'] = True \n",
    "def is_horizontal(x):\n",
    "    parent = -4\n",
    "    target = -2\n",
    "    acquiror = -3\n",
    "    horizontal = -1\n",
    "    target_sic = 19\n",
    "    acquiror_sic = 27\n",
    "    for element in x[acquiror]:\n",
    "        if element in x[target] :\n",
    "            x[horizontal] = True \n",
    "        else : \n",
    "            x[horizontal] = False\n",
    "    if type(x[parent]) == str:\n",
    "        if x[parent] in x[target]:\n",
    "            x[horizontal] = True\n",
    "\n",
    "    for element in x[acquiror_sic]:\n",
    "        if element in x[target_sic]:\n",
    "            x[horizontal] = True \n",
    "    return x\n",
    "\n",
    "mask_horizontal = df2.apply(is_horizontal, axis = 1) # True si horizontal et False sinon\n",
    "mask_horizontal = mask_horizontal['horizontal']\n",
    "df_horizontal = df2[mask_horizontal]\n",
    "shape_is_horizontal = df_horizontal.shape[0]\n",
    "\n",
    "df_horizontal.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Non horizontal acquisitions\n",
    "mask_non_horizontal = []\n",
    "for i,element in enumerate(mask_horizontal):\n",
    "    mask_non_horizontal.append(not element)\n",
    "df_non_horizontal = df2[mask_non_horizontal]\n",
    "shape_non_horizontal = df_non_horizontal.shape[0]\n",
    "\n",
    "df_non_horizontal.reset_index(inplace = True)\n",
    "df_non_horizontal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each new database, we chose to keep only some columns. \n",
    "For Target_horizontal and Target_non_horizontal, we kept : \"Deal value\\nm EUR\", \"Target country code\", \"Target BvD ID number\", \"Acquiror country code\", \"Completed date\", \"Acquired stake (%)\", \"Final stake (%)\" \\\n",
    "For Acquiror_horizontal and Acquiror_non_horizontal, we kept : \"Deal value\\nm EUR\", \"Target country code\", \"Acquiror country code\", \"Acquiror BvD ID number\", \"Completed date\", \"Acquired stake (%)\", \"Final stake (%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_horizontal = df_horizontal[[\"Deal value\\nm EUR\", \"Target country code\", \"Target BvD ID number\", \"Acquiror country code\", \"Completed date\", \"Acquired stake (%)\", \"Final stake (%)\"]]\n",
    "Acquiror_horizontal = df_horizontal[[\"Deal value\\nm EUR\", \"Target country code\", \"Acquiror country code\", \"Acquiror BvD ID number\", \"Completed date\", \"Acquired stake (%)\", \"Final stake (%)\"]]\n",
    "Target_non_horizontal = df_non_horizontal[[\"Deal value\\nm EUR\", \"Target country code\", \"Target BvD ID number\", \"Acquiror country code\", \"Completed date\", \"Acquired stake (%)\", \"Final stake (%)\"]]\n",
    "Acquiror_non_horizontal = df_non_horizontal[[\"Deal value\\nm EUR\", \"Target country code\", \"Acquiror country code\", \"Acquiror BvD ID number\", \"Completed date\", \"Acquired stake (%)\", \"Final stake (%)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportation to .csv\n",
    "Target_horizontal.to_csv('target_horizontal.csv', index = True)\n",
    "Acquiror_horizontal.to_csv('acquiror_horizontal.csv', index = True)\n",
    "Target_non_horizontal.to_csv('target_non_horizontal.csv', index = True)\n",
    "Acquiror_non_horizontal.to_csv('acquiror_non_horizontal.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collecting and extracting data from Orbis** \\\n",
    "From now one, we had to find data about the companies : number of employees, R&D expenses ... Those data were available on Orbis through a remote Desktop. We download data regarding : ......... for every company of the 30 first countries. Those databases are in the folder 'DATABASE_Orbis', sorted country by country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On charge les 4 fichiers\n",
    "df_H_target = pd.read_csv(\"target_horizontal.csv\")\n",
    "df_NH_target = pd.read_csv(\"target_non_horizontal.csv\")\n",
    "df_H_acquiror = pd.read_csv(\"acquiror_horizontal.csv\")\n",
    "df_NH_acquiror = pd.read_csv(\"acquiror_non_horizontal.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **first step** was to concatenate the excel files in 'DATABASE_Obis'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"DATABASE_Orbis\"\n",
    "folder = os.listdir(path)\n",
    "data_r_d = pd.DataFrame()\n",
    "for file in folder :\n",
    "    data = pd.read_csv(f'{path}/{file}')\n",
    "    data_r_d = data_r_d.append(data)\n",
    "data_r_d\n",
    "# exportation to .csv\n",
    "data_r_d.to_csv('data_r_d.csv')\n",
    "data_r_d = pd.read_csv('data_r_d.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second Step**: \\\n",
    "we had to only keep the date year of the orbis database ('data_r_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction that only keep the date year. \n",
    "def keep_year_orbis(x):\n",
    "    x[2] = str(x[2])[:4]\n",
    "    return x\n",
    "\n",
    "def keep_year_zephir(x):\n",
    "    x[5] = str(x[5])[:4]\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "#On ne garde que l'année et on retire le mois et le jour\n",
    "data_r_d = data_r_d.apply(keep_year_orbis, axis = 1)\n",
    "data_r_d.set_index([\"bvdid\",\"closing_date\"], inplace=True) \n",
    "data_r_d.drop(labels = 'Unnamed: 0', axis = 1, inplace = True)\n",
    "data_r_d1 = data_r_d.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**third step** \\\n",
    "join the orbis database with the zephir databases.  \n",
    "- 1) join inner with the series of bvdid of orbis and zephir tables on bvdid to keep only the companies that are in both.\n",
    "- 2) join inner with the orbis database the series of bvdid of the table created just before on bvdid to keep only the companies that are in both.\n",
    "- 3) join on bvdid and closing date of the table created in 1) with the Orbis table in order to have every deal with all their r&d informations for the year of the deal. \n",
    "- 4)join on bvdid and closing date of the table created in 3) with the Orbis table in order to have additionnal pieces of information about the company for the year without deal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_final_table(data, name, type) : \n",
    "\n",
    "    \n",
    "    data.rename(columns = {f'{type} BvD ID number' : \"bvdid\", 'Completed date' : \"closing_date\", 'Unnamed: 0': 'Deal_number'}, inplace = True)\n",
    "    data.dropna(axis = 0,subset=[\"closing_date\"], how = 'any',inplace = True)\n",
    "    #On ne garde que l'année et on retire le mois et le jour\n",
    "    data = data.apply(keep_year_zephir, axis = 1)\n",
    "\n",
    "    data.set_index([\"bvdid\",\"closing_date\"], inplace=True)\n",
    "    data1 = data.reset_index()\n",
    "\n",
    "    # join inner sur la serie des bvdid data_r_d et data pour ne garder que les compagnies présentent dans les deux tables. \n",
    "    serie_bvdid_r_d = data_r_d1['bvdid']\n",
    "    # join\n",
    "    data_deals = data1.merge(serie_bvdid_r_d, on =[\"bvdid\"], how = 'inner')\n",
    "    data_deals.reset_index(inplace=True)\n",
    "    data_deals.drop_duplicates(subset = ['bvdid','closing_date',\"Deal_number\",'Deal value\\nm EUR',f'{type} country code','Acquiror country code','Acquired stake (%)','Final stake (%)'], inplace = True)\n",
    "    #création d'un deal_number\n",
    "    data_deals.reset_index(inplace = True)\n",
    "    data_deals.rename(columns = {'level_0':'deal_number'}, inplace = True)\n",
    "    data_deals_bvdid = data_deals['bvdid']\n",
    "\n",
    "    # join inner sur data_r_d et avec bvdid présent dans data et data_r_d pour ne garder que les compagnies présentent dans les deux tables. \n",
    "    data_r_d_deals = data_r_d1.merge(data_deals_bvdid, on = ['bvdid'], how = 'inner')\n",
    "    data_r_d_deals.drop_duplicates(subset = list(data_r_d_deals.columns), inplace = True)\n",
    "\n",
    "    # join sur les bvdid et closing date de la table précédente avec data_r_d pour avoir tous les deals avec leur informations r&d de l'année correspondante. \n",
    "    data_deals.set_index([\"bvdid\",\"closing_date\"], inplace=True)\n",
    "    # join\n",
    "    data_deals_left = data_deals.join(data_r_d, on =[\"bvdid\",'closing_date'], how = 'left')\n",
    "    data_deals_left.reset_index(inplace=True)\n",
    "\n",
    "    # data sur data_r_d_deals\n",
    "    data_r_d_deals.set_index([\"bvdid\",\"closing_date\"], inplace=True)\n",
    "    # join \n",
    "    data_deals_right = data_r_d_deals.join(data, on = [\"bvdid\",\"closing_date\"], how = 'left')\n",
    "    data_deals_right.reset_index(inplace = True)\n",
    "\n",
    "    # reindéxation des colonnes pour que ce soit les même hez right et left\n",
    "    data_deals_left.drop(axis = 1, labels=['index'], inplace = True)\n",
    "    data_deals_left = data_deals_left.reindex(columns = list(data_deals_right.columns))\n",
    "    # concaténation de right et left\n",
    "    data_deals_final = pd.concat([data_deals_left,data_deals_right])\n",
    "    #drop duplicates\n",
    "    data_deals_final.drop_duplicates(inplace = True)\n",
    "    # exportation to .csv\n",
    "    data_deals_final.to_csv(f'{name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_final_table(df_H_target, name = 'horizontal_domestic_target', type = 'Target')\n",
    "creation_final_table(df_NH_target, name = 'non_horizontal_domestic_target', type = 'Target')\n",
    "creation_final_table(df_H_acquiror, name = 'horizontal_domestic_acquiror', type = 'Acquiror')\n",
    "creation_final_table(df_NH_acquiror, name = 'non_horizontal_domestic_acquiror', type = 'Acquiror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation\n",
    "df_H_target = pd.read_csv('horizontal_domestic_target.csv')\n",
    "df_NH_target = pd.read_csv('non_horizontal_domestic_target.csv')\n",
    "df_H_acquiror = pd.read_csv('horizontal_domestic_acquiror.csv')\n",
    "df_NH_acquiror = pd.read_csv('non_horizontal_domestic_acquiror.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_value(x):\n",
    "    if type (x) == str:\n",
    "        if '*' in x:\n",
    "            x = x[:-1]\n",
    "        x = float(x)\n",
    "    return x\n",
    "\n",
    "df_H_target['Deal value\\nm EUR'] = df_H_target['Deal value\\nm EUR'].map(deal_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization \n",
    "from sklearn import preprocessing\n",
    "serie = df_H_target['r_d_expenses_operating_revenue']\n",
    "df_H_target['r_d_expenses_operating_revenue']=(serie-serie.mean())/serie.std()\n",
    "def normalization(data):\n",
    "    serie = data['r_d_expenses_operating_revenue']\n",
    "    data['r_d_expenses_operating_revenue']=(serie-serie.mean())/serie.std()\n",
    "#    data['r_d_expenses_operating_revenue'] = preprocessing.normalize(np.array(data['r_d_expenses_operating_revenue']))[0,:]\n",
    "#    data['research_development_expenses'] = preprocessing.normalize(np.array(data['research_development_expenses']))[0,:]\n",
    "    #data['Deal value\\nm EUR'] = preprocessing.normalize(np.array(data['Deal value\\nm EUR']))[0,:]\n",
    "    #data['number_of_employees'] = preprocessing.normalize(np.array(data['number_of_employees']))[0,:]\n",
    "    #data['ebitda'] = preprocessing.normalize(np.array(data['ebitda']))[0,:]\n",
    "    #data['Score-protecting minority investors'] = preprocessing.normalize(np.array(data['Score-protecting minority investors']))[0,:]\n",
    "\n",
    "normalization(df_H_target)\n",
    "normalization(df_NH_target)\n",
    "normalization(df_H_acquiror)\n",
    "normalization(df_NH_acquiror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/1142177735.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Acquired stake (%)_0_10'] = np.where(data['Acquired stake (%)'] <= 10, 1,0)\n",
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/1142177735.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Acquired stake (%)_10_20'] = np.where((data['Acquired stake (%)'] <= 20) & (data['Acquired stake (%)'] > 10), 1,0)\n",
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/1142177735.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Acquired stake (%)_20_30'] = np.where((data['Acquired stake (%)'] <= 30) & (data['Acquired stake (%)'] > 20), 1,0)\n",
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/1142177735.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Acquired stake (%)_30_40'] = np.where((data['Acquired stake (%)'] <= 40) & (data['Acquired stake (%)'] > 30), 1,0)\n",
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/1142177735.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Acquired stake (%)_40_50'] = np.where((data['Acquired stake (%)'] <= 50) & (data['Acquired stake (%)'] > 40), 1,0)\n",
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/1142177735.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Acquired stake (%)_0_25'] = np.where(data['Acquired stake (%)'] <= 25 , 1,0)\n",
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/1142177735.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Acquired stake (%)_25_50'] = np.where(data['Acquired stake (%)'] > 25, 1,0)\n",
      "/var/folders/td/010hh4vx7gl3pcc1zz9bfdlh0000gn/T/ipykernel_38513/1142177735.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Acquired stake (%)_0_50'] = np.where(data['Acquired stake (%)'] > 0, 1,0)\n"
     ]
    }
   ],
   "source": [
    "def aggregate(data):\n",
    "    # keep only corporate firms\n",
    "    data = data[data['type_of_entity'] == 'Corporate']\n",
    "\n",
    "\n",
    "    # dummy variables for acquired stake\n",
    "    data['Acquired stake (%)_0_10'] = np.where(data['Acquired stake (%)'] <= 10, 1,0)\n",
    "    data['Acquired stake (%)_10_20'] = np.where((data['Acquired stake (%)'] <= 20) & (data['Acquired stake (%)'] > 10), 1,0)\n",
    "    data['Acquired stake (%)_20_30'] = np.where((data['Acquired stake (%)'] <= 30) & (data['Acquired stake (%)'] > 20), 1,0)\n",
    "    data['Acquired stake (%)_30_40'] = np.where((data['Acquired stake (%)'] <= 40) & (data['Acquired stake (%)'] > 30), 1,0)\n",
    "    data['Acquired stake (%)_40_50'] = np.where((data['Acquired stake (%)'] <= 50) & (data['Acquired stake (%)'] > 40), 1,0)\n",
    "    data['Acquired stake (%)_0_25'] = np.where(data['Acquired stake (%)'] <= 25 , 1,0)\n",
    "    data['Acquired stake (%)_25_50'] = np.where(data['Acquired stake (%)'] > 25, 1,0)\n",
    "    data['Acquired stake (%)_0_50'] = np.where(data['Acquired stake (%)'] > 0, 1,0)\n",
    "\n",
    "    def fonction_acquired (x, i):\n",
    "        Acquired_stake = x[13]\n",
    "        deal_number = x[9]\n",
    "        if deal_number in s : \n",
    "            x[-i] = 0\n",
    "        else : \n",
    "            if x[-i] == 1:\n",
    "                s.add(deal_number)\n",
    "        return x\n",
    "\n",
    "    for k in range(1,8):\n",
    "        s = set()\n",
    "        data = data.apply(lambda x: fonction_acquired(x,k), axis=1)\n",
    "\n",
    "       # sum of deal value for each slice\n",
    "    data['Total deal value for Acquired stake (%)0_10'] = np.where(data['Acquired stake (%)'] <= 10, data['Deal value\\nm EUR'],1,0)\n",
    "    data['Total deal value for Acquired stake (%)_10_20'] = np.where((data['Acquired stake (%)'] <= 20) & (data['Acquired stake (%)'] > 10), data['Deal value\\nm EUR'],1,0)\n",
    "    data['Total deal value for Acquired stake (%)_20_30'] = np.where((data['Acquired stake (%)'] <= 30) & (data['Acquired stake (%)'] > 20), data['Deal value\\nm EUR'],1,0)\n",
    "    data['Total deal value for Acquired stake (%)_30_40'] = np.where((data['Acquired stake (%)'] <= 40) & (data['Acquired stake (%)'] > 30), data['Deal value\\nm EUR']1,,0)\n",
    "    data['Total deal value for Acquired stake (%)_40_50'] = np.where((data['Acquired stake (%)'] <= 50) & (data['Acquired stake (%)'] > 40), data['Deal value\\nm EUR']1,,0)\n",
    "    data['Total deal value for Acquired stake (%)_0_25'] = np.where(data['Acquired stake (%)'] <= 25 , data['Deal value\\nm EUR'],1,0)\n",
    "    data['Total deal value for Acquired stake (%)_25_50'] = np.where(data['Acquired stake (%)'] > 25, data['Deal value\\nm EUR'],1,0)\n",
    "    data['Total deal value for Acquired stake (%)_0_50'] = np.where(data['Acquired stake (%)'] > 0, data['Deal value\\nm EUR'],1,0)\n",
    "\n",
    "    def fonction_total_deal(x, i):\n",
    "        Acquired_stake = x[13]\n",
    "        deal_number = x[9]\n",
    "        if deal_number in s : \n",
    "            x[-i] = 0\n",
    "        else : \n",
    "            if x[-i] != 0:\n",
    "                s.add(deal_number)\n",
    "        return x\n",
    "\n",
    "    for k in range(1,8):\n",
    "        s = set()\n",
    "        data = data.apply(lambda x: fonction_total_deal(x,k), axis=1)\n",
    "\n",
    "    \n",
    "    # dummy variables for final stake\n",
    "    data['Final stake (%)_0_10'] = np.where(data['Final stake (%)'] <= 10, 1,0)\n",
    "    data['Final stake (%)_10_20'] = np.where((data['Final stake (%)'] <= 20) & (data['Final stake (%)'] > 10), 1,0)\n",
    "    data['Final stake (%)_20_30'] = np.where((data['Final stake (%)'] <= 30) & (data['Final stake (%)'] > 20), 1,0)\n",
    "    data['Final stake (%)_30_40'] = np.where((data['Final stake (%)'] <= 40) & (data['Final stake (%)'] > 30), 1,0)\n",
    "    data['Final stake (%)_40_50'] = np.where((data['Final stake (%)'] <= 50) & (data['Final stake (%)'] > 40), 1,0)\n",
    "    data['Final stake (%)_0_25'] = np.where(data['Final stake (%)'] <= 25 , 1,0)\n",
    "    data['Final stake (%)_25_50'] = np.where(data['Final stake (%)'] > 25, 1,0)\n",
    "\n",
    "    \n",
    "\n",
    "    def fonction_final (x, i):\n",
    "        final_stake = x[14]\n",
    "        deal_number = x[9]\n",
    "        if deal_number in s : \n",
    "            x[-i] = 0\n",
    "        else : \n",
    "            if x[-i] == 1:\n",
    "                s.add(deal_number)\n",
    "        return x\n",
    "\n",
    "    for k in range(1,8):\n",
    "        s = set()\n",
    "        data = data.apply(lambda x: fonction_final(x,k), axis=1)\n",
    "\n",
    "\n",
    "    # mettre un country code à toutes les lignes en se basant sur celui du bvdid\n",
    "    data['countrycode'] = data['bvdid']\n",
    "    def bvdid_to_country_code(x):\n",
    "        x = x[:2]\n",
    "        return x\n",
    "    data['countrycode'] = data['countrycode'].map(bvdid_to_country_code)\n",
    "\n",
    "    # aggregate each row where country and date are the same\n",
    "    data.drop(['Deal_number','Acquired stake (%)','Final stake (%)','Unnamed: 0'], axis = 1, inplace=True)\n",
    "    df_by_country_date = data.groupby(['countrycode','closing_date']).sum()\n",
    "    return df_by_country_date\n",
    "\n",
    "#Apply the function to the tables\n",
    "new_df_NH_target = aggregate(df_NH_target)\n",
    "new_df_H_target = aggregate(df_H_target)\n",
    "new_df_H_acquiror = aggregate(df_H_acquiror)\n",
    "new_df_NH_acquiror = aggregate(df_NH_acquiror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADD REFORM INFORMATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the 2 columns with reforms\n",
    "\n",
    "#Add country protecting index :\n",
    "\n",
    "df_reforms = pd.read_csv(\"score_protect_ms_final.csv\")\n",
    "df_reforms.drop(['Unnamed: 0','Unnamed: 0.1', 'Economy'], axis = 1, inplace = True)\n",
    "df_reforms.rename(columns = {\"Country code\" : \"countrycode\", \"DB year\" : \"closing_date\"}, inplace = True)\n",
    "df_reforms.set_index([\"countrycode\",\"closing_date\"], inplace = True)\n",
    "\n",
    "#Add country reform :\n",
    "df_ref = pd.read_csv(\"country_reform.csv\", sep = \";\")\n",
    "df_ref.drop(['Coutry '], axis = 1, inplace = True)\n",
    "df_ref[\"is_reform\"] = True\n",
    "df_ref.rename(columns = {'Year ': \"closing_date\", \"Country code\" : \"countrycode\"}, inplace = True)\n",
    "df_ref.set_index([\"closing_date\", \"countrycode\"], inplace = True)\n",
    "df_reforms = df_reforms.join(df_ref, on = [\"closing_date\", \"countrycode\"])\n",
    "\n",
    "#Add the columns of cumulative reform\n",
    "time = 0\n",
    "for i in range(1,df.shape[0]-1):\n",
    "    country = df['countrycode'][i]\n",
    "    country_before = df['countrycode'][i-1]\n",
    "    if country == country_before :\n",
    "        if df['is_reform'][i] == 1:\n",
    "            time +=1\n",
    "        if time == 1 :\n",
    "            df['reform1'][i] = 1\n",
    "        if time == 2 :\n",
    "            df['reform2'][i] = 1\n",
    "            df['reform1'][i] = 1\n",
    "\n",
    "    else :\n",
    "        time = 0\n",
    "        if df['is_reform'][i] == 1:\n",
    "            time +=1\n",
    "        if time == 1 :\n",
    "            df['reform1'][i] = 1\n",
    "        if time == 2 :\n",
    "            df['reform2'][i] = 1\n",
    "            df['reform1'][i] = 1\n",
    "\n",
    "\n",
    "#Join final table with the one containing reform score\n",
    "new_df_H_target = new_df_H_target.join(df_reforms, on = [\"countrycode\",\"closing_date\"], how = \"left\")\n",
    "new_df_NH_target = new_df_NH_target.join(df_reforms, on = [\"countrycode\",\"closing_date\"], how = \"left\")\n",
    "new_df_H_acquiror = new_df_H_acquiror.join(df_reforms, on = [\"countrycode\",\"closing_date\"], how = \"left\")\n",
    "new_df_NH_acquiror = new_df_NH_acquiror.join(df_reforms, on = [\"countrycode\",\"closing_date\"], how = \"left\")\n",
    "\n",
    "#Creation of final csv\n",
    "new_df_H_target.to_csv(\"H_target_final.csv\")\n",
    "new_df_H_acquiror.to_csv(\"H_acquiror_final.csv\")\n",
    "new_df_NH_target.to_csv(\"NH_target_final.csv\")\n",
    "new_df_NH_acquiror.to_csv(\"NH_acquiror_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('python-advanced-eval')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce969d991fcfc6f26d7c8788a3ce19e2c9c9571102649c54f14f9c03b583746b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
